\section{Search}
\label{section:search}

The core function of \textit{GESTALT} is to perform last-mile search given partial or uncertain information.
The user is assumed to know the general region of interest and some information about the objects at the location they seek.
Under these conditions, the search problem can be framed in several ways, which we describe below in increasing order of complexity and utility.

\subsection{Search Dataset}
We hand labeled the ground truth responses for 24 spatial queries on object configurations for objects belonging to 6 wineries in the Swan Valley Wineries dataset. 
For reproducibility, we provide the KML file generated by the labelling process, the queries in the form of object names and their spatial configurations, as well as the expected results set for each query.

\subsection{Search Method}

\subsubsection{\textbf{Exact membership search}}
The simplest search function in \emph{GESTALT} (Algorithm \ref{alg:search}) takes a set of query terms representing objects the user knows are at a location, and performs the appropriate look-ups and set intersections to determine which locations are a match for containing \textit{all} those objects.

\begin{algorithm}
    \caption{Membership Search}\label{alg:search}
    \begin{algorithmic}
        \State{\textit{\textbf{Q} a list of query terms to search for}}
        \State{\textit{\textbf{II} an inverted index with objects as keys and locations as values}}
        \State{- - - - -}
        \Procedure{Search}{$Q$, $II$}
            \State{$SearchResult$ $\leftarrow$ []}
            \For{Each $P$ in $Q$}
                \State{Retrieve set of Locations $II$[$P$] and add to $SearchResult$}
            \EndFor
            \State{\textbf{return} intersection of sets of Locations in $SearchResult$}
            \EndProcedure
    \end{algorithmic}
\end{algorithm}

%A \textit{set membership problem} is the most straightforward and most efficient. Given a set of locations, each of which has a set of objects it 'owns' and a set of objects in the search term, which locations have complete coverage of the search set.
\subsubsection{\textbf{Ranked membership search}}
When the exact membership search returns a large number of hits, such as for a broad query (i.e. Which locations have a tree and a bench?) the ranking of those locations can help narrow the results. Using Algorithm \ref{alg:rank}, we aggregate the confidence scores from the object tagging and ownership assignment stages to determine the overall likelihood that a given location contains the object of interest. These scores are then aggregated per location for the relevant query objects, and the final scores determine the ranking of the results. 

\begin{algorithm}[H]
    \caption{Ranked Membership Search}\label{alg:rank}
    \begin{algorithmic}
        \State{\textit{\textbf{Q} a list of query terms to search for}}
        \State{\textit{\textbf{II} an inverted index with objects as keys and locations as values}}
        \State{\textit{\textbf{SearchResult}} Set of candidate locations returned from \textbf{SEARCH()}}
        \State{- - - - -}
        \Procedure{Rank}{$SearchResult$, $Q$, $II$}%\Comment{$S$ results from $Q$ query terms in $II$}
            \State{$RankedSearchResult$ $\leftarrow$ Empty Ordered Dictionary}%\Comment{\textbf{L}ocation \textbf{R}ank}
            \For{Each location $Loc$ in $SearchResult$}%\Comment{\textbf{L}ocation}
                \State{$prob$ $\leftarrow$ 1}%\Comment{Probability location correct}
                \For{Each query point $P$ in $Q$}
                    %\State{$OP$ = Prob of Obj@Locin $II$}\Comment{$OP$ = \textbf{O}bject \textbf{P}robability}
                    \State{$prob$ $\leftarrow$ $prob$ $\times$ $P.prob$}%\Comment{$P.prob$ = object probability}
                \EndFor
                \State{$RankedSearchResult$[$Loc$] $\leftarrow$ $prob$}
            \EndFor
            \State{$RankedSearchResult \leftarrow$ Sort $RankedSearchResult$ by values}
            \State{\textbf{return} $RankedSearchResult$}
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\subsubsection{\textbf{Fuzzy Membership Search}}
When the exact membership search returns no matching locations, we use a fuzzy search procedure (Algorithm \ref{alg:fuzzySearch}) to find a set of partial match locations based on the most discriminative object(s) in the list of query terms provided. 
The most discriminative terms are emphasized since rare objects are memorable and more uniquely identify locations than common objects do.

\begin{algorithm}
    \caption{Fuzzy Membership Search}\label{alg:fuzzySearch}
    \begin{algorithmic}[2]
        \State{\textit{\textbf{Q} a list of query terms to search for}}
        \State{\textit{\textbf{II} an inverted index with objects as keys and locations as values}}
        \State{- - - - -}
        \Procedure{fuzzySearch}{$Q$,$II$}
            \State{$SearchResult$ $\leftarrow$ \textbf{II.SEARCH}($Q$)}
            \If{$SearchResult$ is Empty}
                \State{$P$ $\leftarrow$ Pop most discriminative term from $Q$}
                \State{$SearchResult$ $\leftarrow$ \textbf{$II$.SEARCH}($Q$)}
                \If{$SearchResult$ is not Empty}
                    \State{Skip to Line 6}
                \Else
                    \State{$SearchResult$ $\leftarrow$ \textbf{II.SEARCH}($Q$.remove($P$)}
                \EndIf
            \EndIf
            \If{$SearchResult$ has more than 1 item}
                \State{\textbf{return} \textbf{$II$.RANK($SearchResult$, $Q$)}}
            \EndIf
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsubsection{\textbf{Spatial Search}}
\nrscomment{high level overview and cite COMPASS}

\begin{figure*}[h]
    \centering
    \begin{subfigure}[t]{.45\textwidth}
        \includesvg[width=\textwidth]{objloc_gestalt.svg}
        \caption{\small A candidate location X has named objects A-D with the spatial layout depicted above.} 
        \label{fig:spatial_search_obj}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.45\textwidth}
        \includesvg[width=\textwidth]{objobj_gestalt.svg}
        \caption{\small The objects are binned into spatial quadrants based on their relative position to the location coordinates, X.} 
        \label{fig:spatial_search_obj}
    \end{subfigure}
    \hfill
    \caption{\textbf{Generate and Query an Object-Location Structure.}}\label{figure:spatial_search} 
\end{figure*}



\subsection{Search Results}

\small{
\begin{table}[h!]
    \begin{center}
        \begin{tabular}{ |c|c|c|c| } 
            \hline
            Query Method & Metric & Results \\
            \hline
            \multirow{2}{7em}{Loc-Obj} & Mean Precision & $0.854$ \\
            & Mean Recall & $0.917$\\%& 
            \hline     
            \multirow{2}{7em}{Obj-Obj} & Mean Precision & $0.721$ \\ 
            &Mean Recall & $0.875$ \\
            \hline
        \end{tabular}
        \caption{Spatial results across 24 ground-truth pictorial queries run on the \textit{combined swan valley wineries} dataset.} %Clustering used DBSCAN with $\epsilon = \frac{0.05}{6371}$ and MinCluster=$3$.} 
        \label{Table:GroundTruth}
    \end{center}
\end{table}
}

To determine the overall recall of \emph{GESTALT}'s spatial search process in a noisy environment, we test the hand-labeled queries on the \textit{Combined} dataset.
The results (Table \ref{Table:GroundTruth}) show that \emph{GESTALT} has a high recall on both methods of query specification, object-location and object-object.
We expect precision to be low on these query results when compared to the ground-truth, since the \textit{Combined} dataset includes many additional locations that were not considered during the hand-labeling.
However, the precision we recorded is reasonable, which points to the discriminative power of spatial configurations of objects as a search constraint.

%ran 12 queries on each pictorial querying method and record the results in table \ref{Table:GroundTruth}. 
%The recall of the Loc-Obj queries tends to increase with the number of query terms, as they are additive. 
%The precision of the obj-obj queries is negatively impacted by single term queries, which returns any location with that object present.

\subsection{Search Complexity}

\small{
\begin{figure}[h]
    \centering
    \begin{subfigure}[t]{.45\textwidth}
        \includesvg[width=\textwidth]{queryExecutionRecall.svg}
        
        %\caption{Additional terms improve precision of results for all techniques except Loc-Obj Pictorial Querying, for which each search term adds to possible matches, rather than pruning impossible matches. Users seeking to prune their search space should seek to input 3 objects to \emph{GESTALT}}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.45\textwidth} 
        \includesvg[width=\textwidth]{queryExecutionTime.svg}
        %\caption{Query time remains constant for Pictorial Obj-Obj querying after a second item because it only requires a single matrix traversal per location to match the query pattern to that candidate location. The set intersections in our Index Searches are order-optimized to execute the most discriminitive sets first in queries.}    
    \end{subfigure}

    \caption{Number of candidate locations and query response times for queries on the Washington D.C. Dataset (12,179 Locations, 91,188 objects).}\label{figure:PerformanceExperiments}\label{fig:queryExecutionRecall}        \label{fig:queryExecutionTime}
    %A suite of queries run across the DC Dataset (12179 Locations, 148 Distinct classes among 91188 objects) clustered using DBSCAN with $\epsilon=0.00000156961$ (roughly 50m),MinCluster=$3$ and out Fuzzy Threshold$=0.0$. We use the 10 most common object classes: (eg crossing, traffic signals, street lamp, bus stop) to simulate worst case conditions where the user recalls almost no distinguishing features of their target location} 
\end{figure}
}

\subsubsection{Theoretical Complexity}
\nrscomment{cite algo analysis in COMPASS}

\nrscomment{do some analysis on membership searches?}


\subsubsection{Empirical Complexity}

Figure \ref{fig:queryExecutionTime} shows the query response times on the Washington D.C. dataset (with over 91,000 objects and 12,000 locations) as the number of query terms increases. 
The queries tested were constructed using the 10 most common object classes: (e.g. crossing, traffic signals, street lamp, bus stop) to simulate worst case conditions where the user recalls no highly distinctive features of their target location.
For the three membership searches (exact, ranked, and fuzzy), the response times decrease as the number of objects specified in the query increases (i.e. as the pool of possible locations meeting the query specification narrows), following the trend in Figure \ref{fig:queryExecutionRecall} which shows the aggressive pruning that takes place as the queries become more specific.
Critically, this same effect is achieved for the object-object spatial search, where the recursive pruning of the search space quickly eliminates any candidates that are not viable matches to the pictorial query specification.
The location-object search does not show this effect because it counts the number of objects matching the query configuration and uses that to rank candidates, so no early stopping is done when the right object is found to the wrong cardinal direction of the location. %which iterates through the quadrants of each location and counts the number of objects matching the directional specification from the query,
%it does not stop early when a candidate does not match on an object, instead returning the count of matches to be used to rank all of the candidates.





%Fuzzy search begins with the most discriminative query term (based on counts maintained by the inverted index) and proceeds by adding query terms successively until the set intersection returns no locations matching all the criteria, at which point it walks back by one term and returns the prvious set of locations, which is the closest match.

%\subsubsection{Scalability}


%on several queries over the Washington D.C. dataset to demonstrate the scalability of the membership search functionality of \emph{GESTALT}. 

%\nrscomment{Kent, plot num locations vs time for fuzzy search runs}
