\section{Introduction}
\label{section:introduction}
Geographic information systems (GIS) provide users with a means to efficiently search over spatial data given information like the coordinates or exact name of a location of interest. 
However, current GIS capabilities do not enable users to search for locations with imperfect or incomplete information easily. 
From psychology and neuroscience research on cognitive maps of terrain for navigation and route planning~\cite{Weisberg2016, Miller2013, Keatley2021}, we know that people anchor memories of a location around its visible objects and landmarks, likely hierarchically or separately relating global and local features~\cite{Weisberg2016}. 
For example, a user may remember a location by a series of visual features encountered near it, like a large building, a bus stop, and a brightly colored sign, but fail to recall its exact address or physical coordinates. 
In these cases, GIS tools may help narrow down the general region of interest, but the user must then perform a manual \emph{last-mile} search to find the exact location of interest within that region. 
Last-mile search involves visually inspecting images to identify distinct landmarks or terrain features that match the partial information about the location. 
The last-mile component of the search process is a bottleneck, as it encumbers the user with the burden of sifting through many possible candidate locations until the correct one is visually identified. 

Last-mile search is a common problem in the open-source intelligence community. Recent related work from \textit{Bellingcat}
highlights the need for search techniques that can accommodate queries for collections of objects in close geographic proximity to each other.
Automating the last-mile search process requires addressing additional criteria, including the relative spatial configuration of objects, uncertainty in the knowledge of a location to allow for partial matches, and accounting for the fuzzy boundaries between locations, where an object may be visible from several nearby locations and can be associated with all of them to maximize the recall of the search result.

We present \emph{GESTALT}\footnote{\url{https://github.com/osullik/GESTALT_GEOSEARCH}}$^,$\footnote{\url{https://gestalt.umiacs.umd.edu/}}, an end-to-end spatial search pipeline inspired by the way humans recall and search for information~\cite{Helbing2020, Oliveira2016, Weisberg2016}.
\emph{GESTALT} extracts geospatial data, transforms it into coherent object and location relations, stores those relations, and enables search. 
Specifically, \emph{GESTALT} provides the following functionality:
\begin{enumerate}
    \item Multiple methods for ingesting location and object tags, including automatic object detection on geotagged images.
    \item Density-based clustering of object tags to fuzzily assign objects to (possibly multiple) nearby locations, enabling users to ask membership questions, like "Which locations contain a swimming pool, a statue, and a palm tree?"
    \item Probabilistic search over locations based on object membership queries and with partial matches when the search constraints are too narrow and ranked results when they are too broad.
    \item A proof-of-concept instance of the \emph{GESTALT} user interface with the Swan Valley and Washington DC regions available at \url{https://gestalt.umiacs.umd.edu}.
\end{enumerate}

We contribute a new hand-labeled \textit{Swan Valley Wineries} dataset for the last-mile spatial search problem and provide a proof of concept implementation of the proposed \emph{GESTALT} architecture. We report the precision and recall on ground truth data and execution performance metrics on a more extensive data set to demonstrate the scalability of our search procedures.

The rest of this paper is organized as follows. In section \ref{section:architecture}, we define the \emph{GESTALT} architecture and discuss how each subsystem contributes to our human-centric approach to automating the last-mile search. 
Next, in section \ref{section:data}, we describe the process used to generate the \textit{Swan Valley Wineries} dataset and extract noisy object tags from geotagged images. Then, we describe the object ownership assignment process in section \ref{section:ownership}, and the search process in \ref{section:search}. 
Finally, we summarize related work in section \ref{section:related} and conclude by identifying future research directions in section \ref{section:conclusion}.









